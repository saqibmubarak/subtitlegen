[MODELS]
# Define available Whisper models. New models can be added here.
# Key: friendly_name = whisper_identifier (or local path to model)
tiny = tiny
base = base
small = small
medium = medium
# Added the recommended model for speed and accuracy (often fits in 8GB VRAM with INT8)
large-turbo = large-v3-turbo

[TRANSCRIPTION]
# Device to use for running the LLM (Whisper model).
# 'cuda' will use your GPU, 'cpu' will use your CPU.
device = cuda

# Which model to use from the [MODELS] section
model_name = large-turbo

# Language of the video, or 'None' for automatic detection.
language = None

# NEW SETTING: Optimization level for GPU.
# 'float16' is standard. 'int8_float16' compresses weights for better VRAM usage (recommended for 8GB GPU).
compute_type = int8_float16

# Number of files to process concurrently (parallel workers). Adjust based on VRAM.
# For 'large-turbo' with int8_float16 on 8GB VRAM, 1-2 workers is safe. For 'small', 3-4 workers is safe.
parallel_workers = 2

[FILES]
# Supported video file extensions (comma-separated, case-insensitive)
video_extensions = .mp4, .mkv, .avi, .mov, .wmv